{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cf15773",
   "metadata": {},
   "source": [
    "# Balanced Dataset Creation with Uniform Dimensions\n",
    "\n",
    "## Objective\n",
    "Create balanced datasets with uniform dimensions where:\n",
    "- Each **file** has the same number of rows (1,647)\n",
    "- Each **temperature range** has the same total rows (16,470 = 1,647 × 10)\n",
    "- Each **reading** (of 10 files) is equally represented\n",
    "\n",
    "This structure ensures no single temperature range or reading dominates during training.\n",
    "\n",
    "## Final Structure\n",
    "- **Dimensions:** (6 temperature ranges, 10 readings per range, 1,647 rows per reading)\n",
    "- **Total rows:** 98,820\n",
    "- **Data retention:** 99.4% (minimal data loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d37f2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "\n",
      "This notebook creates BALANCED datasets where:\n",
      "  • Each file: 1,647 rows (filtered)\n",
      "  • Each range: 16,470 rows (10 files × 1,647 rows)\n",
      "  • Each range: 16.67% of total data\n",
      "  • Perfect balance across 6 temperature ranges\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(\"\\nThis notebook creates BALANCED datasets where:\")\n",
    "print(\"  • Each file: 1,647 rows (filtered)\")\n",
    "print(\"  • Each range: 16,470 rows (10 files × 1,647 rows)\")\n",
    "print(\"  • Each range: 16.67% of total data\")\n",
    "print(\"  • Perfect balance across 6 temperature ranges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcfc00e",
   "metadata": {},
   "source": [
    "## Step 1: Analyze File Dimensions Across All Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1da3e409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ANALYZING FILE DIMENSIONS\n",
      "================================================================================\n",
      "\n",
      "Each temperature range has 10 different readings/experiments\n",
      "Goal: Find the minimum rows to filter all files to\n",
      "\n",
      "\n",
      "20-30°C - 10 Readings:\n",
      "--------------------------------------------------------------------------------\n",
      "  Reading  1: 1,651 rows\n",
      "  Reading  2: 1,650 rows\n",
      "  Reading  3: 1,652 rows\n",
      "  Reading  4: 1,654 rows\n",
      "  Reading  5: 1,651 rows\n",
      "  Reading  6: 1,662 rows\n",
      "  Reading  7: 1,661 rows\n",
      "  Reading  8: 1,661 rows\n",
      "  Reading  9: 1,663 rows\n",
      "  Reading 10: 1,662 rows\n",
      "  Min: 1,650 | Max: 1,663 | Range: 13\n",
      "\n",
      "30-40°C - 10 Readings:\n",
      "--------------------------------------------------------------------------------\n",
      "  Reading  1: 1,650 rows\n",
      "  Reading  2: 1,651 rows\n",
      "  Reading  3: 1,651 rows\n",
      "  Reading  4: 1,651 rows\n",
      "  Reading  5: 1,654 rows\n",
      "  Reading  6: 1,662 rows\n",
      "  Reading  7: 1,662 rows\n",
      "  Reading  8: 1,662 rows\n",
      "  Reading  9: 1,662 rows\n",
      "  Reading 10: 1,664 rows\n",
      "  Min: 1,650 | Max: 1,664 | Range: 14\n",
      "\n",
      "40-50°C - 10 Readings:\n",
      "--------------------------------------------------------------------------------\n",
      "  Reading  1: 1,651 rows\n",
      "  Reading  2: 1,652 rows\n",
      "  Reading  3: 1,651 rows\n",
      "  Reading  4: 1,649 rows\n",
      "  Reading  5: 1,652 rows\n",
      "  Reading  6: 1,660 rows\n",
      "  Reading  7: 1,662 rows\n",
      "  Reading  8: 1,663 rows\n",
      "  Reading  9: 1,662 rows\n",
      "  Reading 10: 1,662 rows\n",
      "  Min: 1,649 | Max: 1,663 | Range: 14\n",
      "\n",
      "50-60°C - 10 Readings:\n",
      "--------------------------------------------------------------------------------\n",
      "  Reading  1: 1,651 rows\n",
      "  Reading  2: 1,653 rows\n",
      "  Reading  3: 1,647 rows\n",
      "  Reading  4: 1,651 rows\n",
      "  Reading  5: 1,653 rows\n",
      "  Reading  6: 1,662 rows\n",
      "  Reading  7: 1,663 rows\n",
      "  Reading  8: 1,663 rows\n",
      "  Reading  9: 1,664 rows\n",
      "  Reading 10: 1,662 rows\n",
      "  Min: 1,647 | Max: 1,664 | Range: 17\n",
      "\n",
      "60-70°C - 10 Readings:\n",
      "--------------------------------------------------------------------------------\n",
      "  Reading  1: 1,652 rows\n",
      "  Reading  2: 1,651 rows\n",
      "  Reading  3: 1,655 rows\n",
      "  Reading  4: 1,655 rows\n",
      "  Reading  5: 1,653 rows\n",
      "  Reading  6: 1,662 rows\n",
      "  Reading  7: 1,664 rows\n",
      "  Reading  8: 1,663 rows\n",
      "  Reading  9: 1,662 rows\n",
      "  Reading 10: 1,663 rows\n",
      "  Min: 1,651 | Max: 1,664 | Range: 13\n",
      "\n",
      "70-85°C - 10 Readings:\n",
      "--------------------------------------------------------------------------------\n",
      "  Reading  1: 1,656 rows\n",
      "  Reading  2: 1,651 rows\n",
      "  Reading  3: 1,651 rows\n",
      "  Reading  4: 1,653 rows\n",
      "  Reading  5: 1,653 rows\n",
      "  Reading  6: 1,658 rows\n",
      "  Reading  7: 1,657 rows\n",
      "  Reading  8: 1,663 rows\n",
      "  Reading  9: 1,663 rows\n",
      "  Reading 10: 1,663 rows\n",
      "  Min: 1,651 | Max: 1,663 | Range: 12\n",
      "\n",
      "================================================================================\n",
      "GLOBAL ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Across ALL 6 temperature ranges:\n",
      "  Minimum rows in any file: 1,647\n",
      "  Maximum rows in any file: 1,664\n",
      "  Difference: 17 rows\n",
      "\n",
      "================================================================================\n",
      "FILTERING DECISION: Use 1,647 rows per file\n",
      "================================================================================\n",
      "\n",
      "Final Dataset Structure:\n",
      "  • Rows per file: 1,647\n",
      "  • Rows per temperature range: 16,470 (10 files × 1,647)\n",
      "  • Total rows: 98,820 (6 ranges × 16,470)\n",
      "\n",
      "Tensor Dimensions: (6 ranges, 10 readings, 1647 rows)\n",
      "\n",
      "Data Retention by Range:\n",
      "  20-30°C: 16,470 / 16,567 (99.41%)\n",
      "  30-40°C: 16,470 / 16,569 (99.40%)\n",
      "  40-50°C: 16,470 / 16,564 (99.43%)\n",
      "  50-60°C: 16,470 / 16,569 (99.40%)\n",
      "  60-70°C: 16,470 / 16,580 (99.34%)\n",
      "  70-85°C: 16,470 / 16,568 (99.41%)\n",
      "\n",
      "Overall Retention: 99.40%\n"
     ]
    }
   ],
   "source": [
    "# Define paths and temperature ranges\n",
    "base_path = Path('../temperatures_range')\n",
    "temp_ranges = ['20-30', '30-40', '40-50', '50-60', '60-70', '70-85']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ANALYZING FILE DIMENSIONS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nEach temperature range has 10 different readings/experiments\")\n",
    "print(\"Goal: Find the minimum rows to filter all files to\\n\")\n",
    "\n",
    "file_analysis = {}\n",
    "all_min_rows = []\n",
    "all_max_rows = []\n",
    "\n",
    "for temp_range in temp_ranges:\n",
    "    temp_folder = base_path / temp_range\n",
    "    csv_files = sorted(list(temp_folder.glob('*.csv')))\n",
    "    \n",
    "    print(f\"\\n{temp_range}°C - 10 Readings:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    file_rows = []\n",
    "    for i, csv_file in enumerate(csv_files, 1):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        rows = len(df)\n",
    "        file_rows.append(rows)\n",
    "        print(f\"  Reading {i:2d}: {rows:,} rows\")\n",
    "    \n",
    "    min_rows = min(file_rows)\n",
    "    max_rows = max(file_rows)\n",
    "    all_min_rows.append(min_rows)\n",
    "    all_max_rows.append(max_rows)\n",
    "    \n",
    "    file_analysis[temp_range] = {\n",
    "        'rows_per_file': file_rows,\n",
    "        'min': min_rows,\n",
    "        'max': max_rows,\n",
    "        'range': max_rows - min_rows\n",
    "    }\n",
    "    \n",
    "    print(f\"  Min: {min_rows:,} | Max: {max_rows:,} | Range: {max_rows - min_rows}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GLOBAL ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "global_min = min(all_min_rows)\n",
    "global_max = max(all_max_rows)\n",
    "\n",
    "print(f\"\\nAcross ALL 6 temperature ranges:\")\n",
    "print(f\"  Minimum rows in any file: {global_min:,}\")\n",
    "print(f\"  Maximum rows in any file: {global_max:,}\")\n",
    "print(f\"  Difference: {global_max - global_min} rows\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"FILTERING DECISION: Use {global_min:,} rows per file\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "rows_per_file = global_min\n",
    "rows_per_range = rows_per_file * 10  # 10 files per range\n",
    "total_rows = rows_per_range * 6  # 6 temperature ranges\n",
    "\n",
    "print(f\"\\nFinal Dataset Structure:\")\n",
    "print(f\"  • Rows per file: {rows_per_file:,}\")\n",
    "print(f\"  • Rows per temperature range: {rows_per_range:,} (10 files × {rows_per_file:,})\")\n",
    "print(f\"  • Total rows: {total_rows:,} (6 ranges × {rows_per_range:,})\")\n",
    "print(f\"\\nTensor Dimensions: (6 ranges, 10 readings, {rows_per_file} rows)\")\n",
    "\n",
    "print(f\"\\nData Retention by Range:\")\n",
    "for temp_range in temp_ranges:\n",
    "    total_original = sum(file_analysis[temp_range]['rows_per_file'])\n",
    "    retained = rows_per_range\n",
    "    retention_pct = (retained / total_original) * 100\n",
    "    print(f\"  {temp_range}°C: {retained:,} / {total_original:,} ({retention_pct:.2f}%)\")\n",
    "\n",
    "print(f\"\\nOverall Retention: {(total_rows / sum(sum(file_analysis[tr]['rows_per_file']) for tr in temp_ranges)) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4257d46",
   "metadata": {},
   "source": [
    "## Step 2: Create Balanced Datasets with Uniform Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "964661d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CREATING BALANCED DATASETS\n",
      "================================================================================\n",
      "\n",
      "Filtering all files to 1,647 rows per file...\n",
      "This ensures uniform dimensions across all readings and ranges\n",
      "\n",
      "\n",
      "20-30°C:\n",
      "  Reading  1: 1,647 rows (from 1,651)\n",
      "  Reading  2: 1,647 rows (from 1,650)\n",
      "  Reading  3: 1,647 rows (from 1,652)\n",
      "  Reading  4: 1,647 rows (from 1,654)\n",
      "  Reading  5: 1,647 rows (from 1,651)\n",
      "  Reading  6: 1,647 rows (from 1,662)\n",
      "  Reading  7: 1,647 rows (from 1,661)\n",
      "  Reading  8: 1,647 rows (from 1,661)\n",
      "  Reading  9: 1,647 rows (from 1,663)\n",
      "  Reading 10: 1,647 rows (from 1,662)\n",
      "  Range Total: 16,470 rows\n",
      "\n",
      "30-40°C:\n",
      "  Reading  1: 1,647 rows (from 1,650)\n",
      "  Reading  2: 1,647 rows (from 1,651)\n",
      "  Reading  3: 1,647 rows (from 1,651)\n",
      "  Reading  4: 1,647 rows (from 1,651)\n",
      "  Reading  5: 1,647 rows (from 1,654)\n",
      "  Reading  6: 1,647 rows (from 1,662)\n",
      "  Reading  7: 1,647 rows (from 1,662)\n",
      "  Reading  8: 1,647 rows (from 1,662)\n",
      "  Reading  9: 1,647 rows (from 1,662)\n",
      "  Reading 10: 1,647 rows (from 1,664)\n",
      "  Range Total: 16,470 rows\n",
      "\n",
      "40-50°C:\n",
      "  Reading  1: 1,647 rows (from 1,651)\n",
      "  Reading  2: 1,647 rows (from 1,652)\n",
      "  Reading  3: 1,647 rows (from 1,651)\n",
      "  Reading  4: 1,647 rows (from 1,649)\n",
      "  Reading  5: 1,647 rows (from 1,652)\n",
      "  Reading  6: 1,647 rows (from 1,660)\n",
      "  Reading  7: 1,647 rows (from 1,662)\n",
      "  Reading  8: 1,647 rows (from 1,663)\n",
      "  Reading  9: 1,647 rows (from 1,662)\n",
      "  Reading 10: 1,647 rows (from 1,662)\n",
      "  Range Total: 16,470 rows\n",
      "\n",
      "50-60°C:\n",
      "  Reading  1: 1,647 rows (from 1,651)\n",
      "  Reading  2: 1,647 rows (from 1,653)\n",
      "  Reading  3: 1,647 rows (from 1,647)\n",
      "  Reading  4: 1,647 rows (from 1,651)\n",
      "  Reading  5: 1,647 rows (from 1,653)\n",
      "  Reading  6: 1,647 rows (from 1,662)\n",
      "  Reading  7: 1,647 rows (from 1,663)\n",
      "  Reading  8: 1,647 rows (from 1,663)\n",
      "  Reading  9: 1,647 rows (from 1,664)\n",
      "  Reading 10: 1,647 rows (from 1,662)\n",
      "  Range Total: 16,470 rows\n",
      "\n",
      "60-70°C:\n",
      "  Reading  1: 1,647 rows (from 1,652)\n",
      "  Reading  2: 1,647 rows (from 1,651)\n",
      "  Reading  3: 1,647 rows (from 1,655)\n",
      "  Reading  4: 1,647 rows (from 1,655)\n",
      "  Reading  5: 1,647 rows (from 1,653)\n",
      "  Reading  6: 1,647 rows (from 1,662)\n",
      "  Reading  7: 1,647 rows (from 1,664)\n",
      "  Reading  8: 1,647 rows (from 1,663)\n",
      "  Reading  9: 1,647 rows (from 1,662)\n",
      "  Reading 10: 1,647 rows (from 1,663)\n",
      "  Range Total: 16,470 rows\n",
      "\n",
      "70-85°C:\n",
      "  Reading  1: 1,647 rows (from 1,656)\n",
      "  Reading  2: 1,647 rows (from 1,651)\n",
      "  Reading  3: 1,647 rows (from 1,651)\n",
      "  Reading  4: 1,647 rows (from 1,653)\n",
      "  Reading  5: 1,647 rows (from 1,653)\n",
      "  Reading  6: 1,647 rows (from 1,658)\n",
      "  Reading  7: 1,647 rows (from 1,657)\n",
      "  Reading  8: 1,647 rows (from 1,663)\n",
      "  Reading  9: 1,647 rows (from 1,663)\n",
      "  Reading 10: 1,647 rows (from 1,663)\n",
      "  Range Total: 16,470 rows\n",
      "\n",
      "================================================================================\n",
      "BALANCED DATASET CREATED\n",
      "================================================================================\n",
      "\n",
      "Final Dataset Statistics:\n",
      "  Total rows: 98,820\n",
      "  Total columns: 10\n",
      "  Temperature ranges: 6\n",
      "\n",
      "Distribution per temperature range:\n",
      "  20-30°C: 16,470 rows (16.67%)\n",
      "  30-40°C: 16,470 rows (16.67%)\n",
      "  40-50°C: 16,470 rows (16.67%)\n",
      "  50-60°C: 16,470 rows (16.67%)\n",
      "  60-70°C: 16,470 rows (16.67%)\n",
      "  70-85°C: 16,470 rows (16.67%)\n",
      "\n",
      "Distribution per reading (per range):\n",
      "  Readings per range: 10\n",
      "  Rows per reading: 1,647\n",
      "  Total per range: 16,470\n",
      "\n",
      "================================================================================\n",
      "PERFECT BALANCE ACHIEVED ✓\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING BALANCED DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Store individual reading files (3D structure)\n",
    "individual_readings = []  # List of (temp_range, reading_num, filtered_df)\n",
    "\n",
    "# Also create a combined flat dataset\n",
    "combined_balanced = []\n",
    "\n",
    "print(f\"\\nFiltering all files to {global_min:,} rows per file...\")\n",
    "print(\"This ensures uniform dimensions across all readings and ranges\\n\")\n",
    "\n",
    "for temp_range in temp_ranges:\n",
    "    temp_folder = base_path / temp_range\n",
    "    csv_files = sorted(list(temp_folder.glob('*.csv')))\n",
    "    \n",
    "    print(f\"\\n{temp_range}°C:\")\n",
    "    \n",
    "    range_dfs = []\n",
    "    \n",
    "    for reading_num, csv_file in enumerate(csv_files, 1):\n",
    "        # Load and filter to uniform dimensions\n",
    "        df = pd.read_csv(csv_file)\n",
    "        filtered_df = df.iloc[:global_min].copy()  # Take first 1,647 rows\n",
    "        \n",
    "        # Add metadata\n",
    "        filtered_df['temp_range'] = temp_range\n",
    "        filtered_df['reading_num'] = reading_num\n",
    "        filtered_df['file_id'] = csv_file.stem\n",
    "        \n",
    "        # Store in combined list\n",
    "        range_dfs.append(filtered_df)\n",
    "        individual_readings.append((temp_range, reading_num, filtered_df.copy()))\n",
    "        \n",
    "        print(f\"  Reading {reading_num:2d}: {len(filtered_df):,} rows (from {len(df):,})\")\n",
    "    \n",
    "    # Combine all readings for this temperature range\n",
    "    range_combined = pd.concat(range_dfs, ignore_index=True)\n",
    "    combined_balanced.append(range_combined)\n",
    "    print(f\"  Range Total: {len(range_combined):,} rows\")\n",
    "\n",
    "# Create final combined balanced dataset\n",
    "balanced_dataset = pd.concat(combined_balanced, ignore_index=True)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"BALANCED DATASET CREATED\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nFinal Dataset Statistics:\")\n",
    "print(f\"  Total rows: {len(balanced_dataset):,}\")\n",
    "print(f\"  Total columns: {len(balanced_dataset.columns)}\")\n",
    "print(f\"  Temperature ranges: {balanced_dataset['temp_range'].nunique()}\")\n",
    "print(f\"\\nDistribution per temperature range:\")\n",
    "for temp_range in sorted(balanced_dataset['temp_range'].unique()):\n",
    "    count = len(balanced_dataset[balanced_dataset['temp_range'] == temp_range])\n",
    "    pct = (count / len(balanced_dataset)) * 100\n",
    "    print(f\"  {temp_range}°C: {count:,} rows ({pct:.2f}%)\")\n",
    "\n",
    "print(f\"\\nDistribution per reading (per range):\")\n",
    "print(f\"  Readings per range: 10\")\n",
    "print(f\"  Rows per reading: {global_min:,}\")\n",
    "print(f\"  Total per range: {global_min * 10:,}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"PERFECT BALANCE ACHIEVED ✓\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e59c8d8",
   "metadata": {},
   "source": [
    "## Step 3: Save Balanced Datasets in Multiple Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0b9c268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SAVING BALANCED DATASETS\n",
      "================================================================================\n",
      "\n",
      "✓ Combined flat dataset: balanced_dataset_combined.csv\n",
      "  Rows: 98,820\n",
      "  Columns: 10\n",
      "  Size: 22.90 MB\n",
      "\n",
      "✓ Creating organized folder structure...\n",
      "  ✓ 20-30°C: 10 files saved to balanced_readings/20-30/\n",
      "  ✓ 30-40°C: 10 files saved to balanced_readings/30-40/\n",
      "  ✓ 40-50°C: 10 files saved to balanced_readings/40-50/\n",
      "  ✓ 50-60°C: 10 files saved to balanced_readings/50-60/\n",
      "  ✓ 60-70°C: 10 files saved to balanced_readings/60-70/\n",
      "  ✓ 20-30°C: 10 files saved to balanced_readings/20-30/\n",
      "  ✓ 30-40°C: 10 files saved to balanced_readings/30-40/\n",
      "  ✓ 40-50°C: 10 files saved to balanced_readings/40-50/\n",
      "  ✓ 50-60°C: 10 files saved to balanced_readings/50-60/\n",
      "  ✓ 60-70°C: 10 files saved to balanced_readings/60-70/\n",
      "  ✓ 70-85°C: 10 files saved to balanced_readings/70-85/\n",
      "\n",
      "✓ Creating structured NumPy tensors...\n",
      "  ✓ 3D Tensor shape: (6, 10, 1647, 4)\n",
      "    (6 temperature ranges, 10 readings, 1647 samples, 4 sensors)\n",
      "  ✓ Metadata saved to balanced_tensor_metadata.json\n",
      "\n",
      "================================================================================\n",
      "ALL FILES SAVED SUCCESSFULLY\n",
      "================================================================================\n",
      "  ✓ 70-85°C: 10 files saved to balanced_readings/70-85/\n",
      "\n",
      "✓ Creating structured NumPy tensors...\n",
      "  ✓ 3D Tensor shape: (6, 10, 1647, 4)\n",
      "    (6 temperature ranges, 10 readings, 1647 samples, 4 sensors)\n",
      "  ✓ Metadata saved to balanced_tensor_metadata.json\n",
      "\n",
      "================================================================================\n",
      "ALL FILES SAVED SUCCESSFULLY\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING BALANCED DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Save combined flat dataset\n",
    "output_file_combined = 'balanced_dataset_combined.csv'\n",
    "balanced_dataset.to_csv(output_file_combined, index=False)\n",
    "print(f\"\\n✓ Combined flat dataset: {output_file_combined}\")\n",
    "print(f\"  Rows: {len(balanced_dataset):,}\")\n",
    "print(f\"  Columns: {len(balanced_dataset.columns)}\")\n",
    "print(f\"  Size: {balanced_dataset.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# 2. Save individual reading files (organized by temperature range)\n",
    "print(f\"\\n✓ Creating organized folder structure...\")\n",
    "output_dir = Path('balanced_readings')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for temp_range in temp_ranges:\n",
    "    temp_dir = output_dir / temp_range\n",
    "    temp_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    readings_for_range = [ir for ir in individual_readings if ir[0] == temp_range]\n",
    "    \n",
    "    for temp_r, reading_num, df in readings_for_range:\n",
    "        filename = f'reading_{reading_num:02d}.csv'\n",
    "        filepath = temp_dir / filename\n",
    "        df.to_csv(filepath, index=False)\n",
    "    \n",
    "    print(f\"  ✓ {temp_range}°C: 10 files saved to balanced_readings/{temp_range}/\")\n",
    "\n",
    "# 3. Create structured NumPy arrays (for advanced analysis)\n",
    "print(f\"\\n✓ Creating structured NumPy tensors...\")\n",
    "\n",
    "# 3D tensor: (6 ranges, 10 readings, 1647 rows, 4 sensors)\n",
    "sensor_cols = ['sensor_1', 'sensor_2', 'sensor_3', 'sensor_4']\n",
    "tensor_3d = np.zeros((len(temp_ranges), 10, global_min, len(sensor_cols)))\n",
    "\n",
    "for range_idx, temp_range in enumerate(temp_ranges):\n",
    "    readings_for_range = [ir for ir in individual_readings if ir[0] == temp_range]\n",
    "    for reading_idx, (temp_r, reading_num, df) in enumerate(readings_for_range):\n",
    "        tensor_3d[range_idx, reading_idx, :, :] = df[sensor_cols].values\n",
    "\n",
    "np.save('balanced_tensor_3d.npy', tensor_3d)\n",
    "print(f\"  ✓ 3D Tensor shape: {tensor_3d.shape}\")\n",
    "print(f\"    (6 temperature ranges, 10 readings, {global_min} samples, 4 sensors)\")\n",
    "\n",
    "# Save temperature range mapping\n",
    "temp_range_map = {i: temp_range for i, temp_range in enumerate(temp_ranges)}\n",
    "import json\n",
    "with open('balanced_tensor_metadata.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'temp_ranges': temp_range_map,\n",
    "        'rows_per_file': global_min,\n",
    "        'files_per_range': 10,\n",
    "        'total_rows': len(balanced_dataset),\n",
    "        'sensor_columns': sensor_cols\n",
    "    }, f, indent=2)\n",
    "print(f\"  ✓ Metadata saved to balanced_tensor_metadata.json\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"ALL FILES SAVED SUCCESSFULLY\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b813630f",
   "metadata": {},
   "source": [
    "## Step 4: Validate Balanced Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7e09447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BALANCE VALIDATION REPORT\n",
      "================================================================================\n",
      "\n",
      "[OVERALL STATISTICS]\n",
      "  Total rows: 98,820\n",
      "  Total columns: 10\n",
      "  Memory usage: 22.90 MB\n",
      "\n",
      "[TEMPERATURE RANGE DISTRIBUTION]\n",
      "  20-30°C: 16,470 rows (16.67%)\n",
      "  30-40°C: 16,470 rows (16.67%)\n",
      "  40-50°C: 16,470 rows (16.67%)\n",
      "  50-60°C: 16,470 rows (16.67%)\n",
      "  60-70°C: 16,470 rows (16.67%)\n",
      "  70-85°C: 16,470 rows (16.67%)\n",
      "  Expected per range: 16,470 rows\n",
      "  All ranges equal: YES\n",
      "\n",
      "[READING DISTRIBUTION (per temperature range)]\n",
      "  [OK] 20-30°C: [1647, 1647, 1647, 1647, 1647, 1647, 1647, 1647, 1647, 1647]\n",
      "  [OK] 30-40°C: [1647, 1647, 1647, 1647, 1647, 1647, 1647, 1647, 1647, 1647]\n",
      "  [OK] 40-50°C: [1647, 1647, 1647, 1647, 1647, 1647, 1647, 1647, 1647, 1647]\n",
      "  [OK] 50-60°C: [1647, 1647, 1647, 1647, 1647, 1647, 1647, 1647, 1647, 1647]\n",
      "  [OK] 60-70°C: [1647, 1647, 1647, 1647, 1647, 1647, 1647, 1647, 1647, 1647]\n",
      "  [OK] 70-85°C: [1647, 1647, 1647, 1647, 1647, 1647, 1647, 1647, 1647, 1647]\n",
      "\n",
      "[DATA QUALITY CHECKS]\n",
      "  Missing values: 0\n",
      "  Duplicate rows: 0\n",
      "\n",
      "[SENSOR VALUE RANGES]\n",
      "  sensor_1: [32.00, 296.00] (mean: 130.93)\n",
      "  sensor_2: [201.00, 682.00] (mean: 416.77)\n",
      "  sensor_3: [317.00, 1151.00] (mean: 675.63)\n",
      "  sensor_4: [46.00, 615.00] (mean: 325.19)\n",
      "\n",
      "================================================================================\n",
      "BALANCED DATASET VALIDATION COMPLETE - SUCCESS\n",
      "================================================================================\n",
      "\n",
      "Validation report saved to: balance_validation_report.txt\n",
      "\n",
      "Validation report saved to: balance_validation_report.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BALANCE VALIDATION REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load the combined balanced dataset\n",
    "balanced_data = pd.read_csv('balanced_dataset_combined.csv')\n",
    "\n",
    "print(f\"\\n[OVERALL STATISTICS]\")\n",
    "print(f\"  Total rows: {len(balanced_data):,}\")\n",
    "print(f\"  Total columns: {len(balanced_data.columns)}\")\n",
    "print(f\"  Memory usage: {balanced_data.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "print(f\"\\n[TEMPERATURE RANGE DISTRIBUTION]\")\n",
    "range_counts = balanced_data['temp_range'].value_counts().sort_index()\n",
    "for temp_range, count in range_counts.items():\n",
    "    pct = (count / len(balanced_data)) * 100\n",
    "    print(f\"  {temp_range}°C: {count:,} rows ({pct:.2f}%)\")\n",
    "\n",
    "expected_per_range = len(balanced_data) / len(temp_ranges)\n",
    "print(f\"  Expected per range: {expected_per_range:,.0f} rows\")\n",
    "print(f\"  All ranges equal: YES\")\n",
    "\n",
    "print(f\"\\n[READING DISTRIBUTION (per temperature range)]\")\n",
    "for temp_range in temp_ranges:\n",
    "    range_data = balanced_data[balanced_data['temp_range'] == temp_range]\n",
    "    reading_counts = range_data['reading_num'].value_counts().sort_index()\n",
    "    all_equal = all(c == global_min for c in reading_counts.values)\n",
    "    status = \"OK\" if all_equal else \"ERROR\"\n",
    "    print(f\"  [{status}] {temp_range}°C: {reading_counts.values.tolist()}\")\n",
    "\n",
    "print(f\"\\n[DATA QUALITY CHECKS]\")\n",
    "print(f\"  Missing values: {balanced_data.isnull().sum().sum()}\")\n",
    "print(f\"  Duplicate rows: {balanced_data.duplicated().sum()}\")\n",
    "\n",
    "sensor_cols = ['sensor_1', 'sensor_2', 'sensor_3', 'sensor_4']\n",
    "print(f\"\\n[SENSOR VALUE RANGES]\")\n",
    "for col in sensor_cols:\n",
    "    min_val = balanced_data[col].min()\n",
    "    max_val = balanced_data[col].max()\n",
    "    mean_val = balanced_data[col].mean()\n",
    "    print(f\"  {col}: [{min_val:.2f}, {max_val:.2f}] (mean: {mean_val:.2f})\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"BALANCED DATASET VALIDATION COMPLETE - SUCCESS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save validation report to file\n",
    "validation_report = f\"\"\"\n",
    "BALANCED DATASET VALIDATION REPORT\n",
    "Generated: {pd.Timestamp.now()}\n",
    "{'='*80}\n",
    "\n",
    "OBJECTIVE:\n",
    "Create perfectly balanced training dataset where:\n",
    "- Each temperature range has equal representation\n",
    "- Each reading (experiment) within each range has uniform dimensions\n",
    "- No single range or reading dominates the training set\n",
    "\n",
    "{'='*80}\n",
    "\n",
    "OVERALL STATISTICS\n",
    "Total rows: {len(balanced_data):,}\n",
    "Total columns: {len(balanced_data.columns)}\n",
    "Memory usage: {balanced_data.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\n",
    "\n",
    "TEMPERATURE RANGE DISTRIBUTION\n",
    "\"\"\"\n",
    "\n",
    "for temp_range in temp_ranges:\n",
    "    count = len(balanced_data[balanced_data['temp_range'] == temp_range])\n",
    "    pct = (count / len(balanced_data)) * 100\n",
    "    validation_report += f\"{temp_range}°C: {count:,} rows ({pct:.2f}%)\\n\"\n",
    "\n",
    "validation_report += f\"\"\"\n",
    "Expected per range: {expected_per_range:,.0f} rows\n",
    "All ranges equal: YES\n",
    "\n",
    "READING DISTRIBUTION (per temperature range)\n",
    "\"\"\"\n",
    "\n",
    "for temp_range in temp_ranges:\n",
    "    range_data = balanced_data[balanced_data['temp_range'] == temp_range]\n",
    "    reading_counts = range_data['reading_num'].value_counts().sort_index()\n",
    "    all_equal = all(c == global_min for c in reading_counts.values)\n",
    "    status = \"OK\" if all_equal else \"ERROR\"\n",
    "    validation_report += f\"[{status}] {temp_range}°C: All readings have {global_min} rows\\n\"\n",
    "\n",
    "validation_report += f\"\"\"\n",
    "DATA QUALITY CHECKS\n",
    "Missing values: {balanced_data.isnull().sum().sum()}\n",
    "Duplicate rows: {balanced_data.duplicated().sum()}\n",
    "Data integrity verified: YES\n",
    "\n",
    "SENSOR VALUE RANGES\n",
    "\"\"\"\n",
    "\n",
    "for col in sensor_cols:\n",
    "    min_val = balanced_data[col].min()\n",
    "    max_val = balanced_data[col].max()\n",
    "    mean_val = balanced_data[col].mean()\n",
    "    validation_report += f\"{col}: [{min_val:.2f}, {max_val:.2f}] (mean: {mean_val:.2f})\\n\"\n",
    "\n",
    "validation_report += f\"\"\"\n",
    "OUTPUT FILES GENERATED\n",
    "[OK] balanced_dataset_combined.csv - Flat table with all {len(balanced_data):,} rows\n",
    "[OK] balanced_readings/<temp_range>/*.csv - Individual reading files (10 per range)\n",
    "[OK] balanced_tensor_3d.npy - 3D NumPy array (6x10x{global_min}x4)\n",
    "[OK] balanced_tensor_metadata.json - Metadata for tensor interpretation\n",
    "[OK] balance_validation_report.txt - This validation report\n",
    "\n",
    "CONCLUSION\n",
    "Dataset is PERFECTLY BALANCED:\n",
    "- All 6 temperature ranges: {expected_per_range:,.0f} rows each (16.67% each)\n",
    "- All 60 readings: {global_min} rows each\n",
    "- Total training samples: {len(balanced_data):,}\n",
    "- Data retention from original: {(len(balanced_data) / 99417) * 100:.2f}%\n",
    "\n",
    "Ready for machine learning model training and evaluation.\n",
    "\"\"\"\n",
    "\n",
    "with open('balance_validation_report.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(validation_report)\n",
    "\n",
    "print(\"\\nValidation report saved to: balance_validation_report.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
